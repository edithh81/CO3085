# ğŸœ Food Order Chatbot with RAG & LLM

A Vietnamese restaurant chatbot using **VinaLlama-2.7B-Chat** with RAG (Retrieval-Augmented Generation) for intelligent menu recommendations and order management.

## ğŸŒŸ Features

- **Menu Information**: Browse and search restaurant menu items
- **Smart Ordering**: Natural language order placement with intent recognition
- **Cart Management**: Add, view, and manage items before checkout
- **Order Confirmation**: Confirm and track orders with database storage
- **RAG-Enhanced**: Uses vector search for relevant menu recommendations
- **Vietnamese Language**: Optimized for Vietnamese conversations

## ğŸ› ï¸ Tech Stack

- **LLM**: VinaLlama-2.7B-Chat (4-bit quantized)
- **Vector DB**: ChromaDB for RAG
- **Embeddings**: Sentence Transformers (paraphrase-multilingual-MiniLM-L12-v2)
- **UI**: Gradio
- **Backend**: SQLite database

## ğŸ“‹ Requirements

### System Requirements
- **GPU**: NVIDIA GPU with 4GB+ VRAM (recommended)
- **RAM**: 8GB+ system RAM
- **Python**: 3.10 or 3.11
- **CUDA**: 11.8+ (for GPU acceleration)

### Python Dependencies
```
torch>=2.0.0
transformers>=4.35.0
sentence-transformers>=2.2.0
chromadb>=0.4.0
gradio>=4.0.0
bitsandbytes>=0.41.0
accelerate>=0.24.0
```

## ğŸš€ Installation

### Option 1: Local Setup

1. **Clone the repository**
```bash
git clone https://github.com/edithh81/CO3085.git
cd CO3085
```

2. **Create virtual environment**
```bash
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Run the application**
```bash
python app.py
```

The app will be available at `http://localhost:7860`

### Option 2: Google Colab (Recommended for limited resources)

Google Colab provides free T4 GPU (15GB VRAM) which is perfect for this project.

1. **Open the notebook**
   - Upload `co3085.ipynb` to Google Colab
   - Or use the link: [Open in Colab](https://colab.research.google.com/)

2. **Enable GPU**
   - Go to `Runtime` â†’ `Change runtime type`
   - Select `T4 GPU` under Hardware accelerator
   - Click `Save`

3. **Run the setup cells**

```python
# Cell 1: Clone repository
!git clone https://github.com/edithh81/CO3085.git
%cd CO3085

# Cell 2: Install dependencies
!pip install -q torch transformers sentence-transformers chromadb gradio bitsandbytes accelerate

# Cell 3: Run the app
!python app.py
```

4. **Access the app**
   - Click on the public URL generated by Gradio (e.g., `https://xxxxx.gradio.live`)
   - The app will be accessible for 72 hours

### Option 3: Colab with Virtual Environment (More Stable)

For better package management in Colab:

```python
# Cell 1: Clone repository
!git clone https://github.com/edithh81/CO3085.git

# Cell 2: Create Python 3.11 virtual environment
!apt install -y python3.11-venv
!python3.11 -m venv /content/rag-venv

# Cell 3: Install dependencies in venv
!/content/rag-venv/bin/pip install -q torch transformers sentence-transformers chromadb gradio bitsandbytes accelerate

# Cell 4: Run the app with venv Python
!MPLBACKEND=Agg /content/rag-venv/bin/python3.11 /content/CO3085/app.py
```

## ğŸ“ Project Structure

```
CO3085/
â”œâ”€â”€ app.py                 # Gradio web interface
â”œâ”€â”€ chatbot.py            # Main chatbot logic with intent parsing
â”œâ”€â”€ llm_handler.py        # LLM model loader and response generation
â”œâ”€â”€ rag_system.py         # RAG implementation with ChromaDB
â”œâ”€â”€ database.py           # SQLite database for orders
â”œâ”€â”€ menu_data.json        # Restaurant menu items
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ co3085.ipynb         # Google Colab notebook
â””â”€â”€ README.md            # This file
```

## ğŸ¯ Usage Examples

### Basic Conversations
```
User: Xin chÃ o
Bot: Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ áº£o cá»§a nhÃ  hÃ ng...

User: Cho tÃ´i xem menu
Bot: ğŸ“‹ THá»°C ÄÆ N NHÃ€ HÃ€NG
     â–¸ MÃ“N CHÃNH
       â€¢ Phá»Ÿ BÃ²...

User: TÃ´i muá»‘n Ä‘áº·t phá»Ÿ bÃ²
Bot: ÄÃ£ thÃªm vÃ o giá» hÃ ng:
     â€¢ Phá»Ÿ BÃ² - 45,000Ä‘
     Tá»•ng cá»™ng: 45,000Ä‘

User: XÃ¡c nháº­n Ä‘Æ¡n hÃ ng
Bot: âœ“ ÄÆ¡n hÃ ng #001 Ä‘Ã£ Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng!
```

### Advanced Features
- **Menu Search**: "CÃ³ mÃ³n nÃ o cÃ³ nÆ°á»›c khÃ´ng?"
- **Price Query**: "GiÃ¡ bÃºn cháº£ bao nhiÃªu?"
- **Cart Management**: "Xem giá» hÃ ng", "ThÃªm 2 ly cÃ  phÃª"
- **Order Cancellation**: "Há»§y Ä‘Æ¡n hÃ ng"

## âš™ï¸ Configuration

### Model Selection
To use a different model, modify `llm_handler.py`:

```python
class LLMHandler:
    def __init__(self, model_name: str = "vilm/vinallama-2.7b-chat"):
        # Change to another model:
        # - "Qwen/Qwen2.5-1.5B-Instruct"
        # - "google/gemma-2b-it"
        # - "microsoft/Phi-3-mini-4k-instruct"
```

### Memory Settings
For limited VRAM, adjust quantization in `llm_handler.py`:

```python
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,  # Use 4-bit for <6GB VRAM
    load_in_8bit=False, # Use 8-bit for 6-12GB VRAM
    # ...
)
```

## ğŸ› Troubleshooting

### Issue: Out of Memory (OOM)
**Solution**: 
- Use 4-bit quantization (already enabled)
- Reduce `max_new_tokens` in `generate_response()`
- Close other GPU applications

### Issue: Model downloads slowly
**Solution**:
- Use Google Colab with good internet
- Pre-download model: `huggingface-cli download vilm/vinallama-2.7b-chat`

### Issue: Response contains system prompts
**Solution**: 
- Already fixed in `_clean_response()` method
- System instructions are filtered out automatically

### Issue: Gradio port already in use
**Solution**:
```python
demo.launch(server_port=7861)  # Change port number
```

## ğŸ“Š Performance

- **Model Size**: ~1.5GB (4-bit quantized from 5.4GB)
- **VRAM Usage**: ~3.5GB on T4 GPU
- **Response Time**: 2-5 seconds per query
- **Accuracy**: ~85% intent recognition for Vietnamese

## ğŸ”„ Updates & Maintenance

### Update Menu Items
Edit `menu_data.json`:
```json
{
  "name": "New Dish Name",
  "category": "Category",
  "price": 50000,
  "description": "Description in Vietnamese"
}
```

Then restart the application.

### Clear Vector Database
```bash
rm -rf chroma_db/  # Delete ChromaDB storage
python app.py      # Will rebuild on startup
```

## ğŸ“ License

MIT License - See LICENSE file for details

## ğŸ‘¥ Contributors

- **Edith** - Initial development

## ğŸ™ Acknowledgments

- **VILM** for VinaLlama-2.7B-Chat model
- **ChromaDB** for vector database
- **Hugging Face** for transformers library
- **Gradio** for web interface

## ğŸ“§ Contact

For issues or questions, please open an issue on GitHub or contact via email.

---

**Note**: This project is for educational purposes (CO3085 - Natural Language Processing course).

